{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db6f2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krish\\.conda\\envs\\dlenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2759d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1aef25569d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53275196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\Datasets\\fashion_mnist\\fashion-mnist_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f201c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbd7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b1ed898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the features\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b492b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b611782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "\n",
    "        super().__init__()\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        #self.features = self.features.to(device=gpu)\n",
    "        #self.labels = self.labels.to(device=gpu)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.features[index].float(), self.labels[index].long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df9e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset(X_train, y_train)\n",
    "test_dataset = customDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d31e46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class artificialNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        for i in range(num_hidden_layers):\n",
    "\n",
    "            layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
    "            layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "            input_dim = neurons_per_layer\n",
    "\n",
    "        layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, features):\n",
    "\n",
    "        return self.model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d7a266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_objective(trial):\n",
    "    \n",
    "    # Search Space\n",
    "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 10)\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 50, 500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_raye\", 0.1, 0.5)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", ['SGD', 'Adam', 'RMSprop', 'Adagrad'])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
    "    neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 256, step=8)\n",
    "\n",
    "    # Static Parameters\n",
    "    input_dim = 784\n",
    "    output_dim = 10\n",
    "\n",
    "    model = artificialNN(input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate)\n",
    "    model = model.to(device=gpu)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if optimizer_name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "\n",
    "            batch_features = batch_features.to(device=gpu)\n",
    "            batch_labels = batch_labels.to(device=gpu)\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(batch_features)\n",
    "            # Loss calculation\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            # Backward Pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # Update grads\n",
    "            optimizer.step()\n",
    "\n",
    "    \n",
    "    # Evaluation steps\n",
    "    model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_features, batch_labels in test_loader:\n",
    "\n",
    "            batch_features = batch_features.to(device=gpu)\n",
    "            batch_labels = batch_labels.to(device=gpu)\n",
    "\n",
    "            output = model(batch_features)\n",
    "            predicted = torch.argmax(output, dim=1)\n",
    "            total += batch_labels.shape[0]\n",
    "            correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "        accuracy = correct/total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba123db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-07 20:58:54,748] A new study created in memory with name: no-name-5bbbf2ea-7153-4f2e-b6f7-bc323953ae66\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "124c7973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-07 21:06:11,423] Trial 0 finished with value: 0.8619166666666667 and parameters: {'num_hidden_layers': 8, 'num_epochs': 479, 'learning_rate': 0.01442945757227185, 'weight_decay': 1.8156641225801864e-05, 'dropout_raye': 0.27083356270565606, 'optimizer': 'RMSprop', 'batch_size': 256, 'neurons_per_layer': 136}. Best is trial 0 with value: 0.8619166666666667.\n",
      "[I 2026-02-07 21:09:33,702] Trial 1 finished with value: 0.8824166666666666 and parameters: {'num_hidden_layers': 8, 'num_epochs': 138, 'learning_rate': 0.0195723520410793, 'weight_decay': 0.00081927381986094, 'dropout_raye': 0.47611194669668133, 'optimizer': 'SGD', 'batch_size': 128, 'neurons_per_layer': 136}. Best is trial 1 with value: 0.8824166666666666.\n",
      "[I 2026-02-07 21:18:22,160] Trial 2 finished with value: 0.20741666666666667 and parameters: {'num_hidden_layers': 7, 'num_epochs': 115, 'learning_rate': 0.03542281620858385, 'weight_decay': 0.0008921187887910298, 'dropout_raye': 0.3223063460092655, 'optimizer': 'RMSprop', 'batch_size': 32, 'neurons_per_layer': 56}. Best is trial 1 with value: 0.8824166666666666.\n",
      "[I 2026-02-07 21:19:06,214] Trial 3 finished with value: 0.8570833333333333 and parameters: {'num_hidden_layers': 1, 'num_epochs': 81, 'learning_rate': 0.01704315361213746, 'weight_decay': 5.7323244128825824e-05, 'dropout_raye': 0.1132669058109451, 'optimizer': 'SGD', 'batch_size': 256, 'neurons_per_layer': 56}. Best is trial 1 with value: 0.8824166666666666.\n",
      "[I 2026-02-07 21:40:28,387] Trial 4 finished with value: 0.534 and parameters: {'num_hidden_layers': 9, 'num_epochs': 428, 'learning_rate': 0.06254487376058049, 'weight_decay': 1.689171272234838e-05, 'dropout_raye': 0.344939261920837, 'optimizer': 'RMSprop', 'batch_size': 64, 'neurons_per_layer': 152}. Best is trial 1 with value: 0.8824166666666666.\n",
      "[I 2026-02-07 21:45:33,246] Trial 5 finished with value: 0.8194166666666667 and parameters: {'num_hidden_layers': 2, 'num_epochs': 202, 'learning_rate': 0.02046619730142575, 'weight_decay': 6.485260813299349e-05, 'dropout_raye': 0.46707507162717266, 'optimizer': 'Adam', 'batch_size': 64, 'neurons_per_layer': 48}. Best is trial 1 with value: 0.8824166666666666.\n",
      "[I 2026-02-07 21:48:58,549] Trial 6 finished with value: 0.7234166666666667 and parameters: {'num_hidden_layers': 10, 'num_epochs': 120, 'learning_rate': 0.05477954055265592, 'weight_decay': 1.9188738312773633e-05, 'dropout_raye': 0.13145499021203585, 'optimizer': 'RMSprop', 'batch_size': 128, 'neurons_per_layer': 96}. Best is trial 1 with value: 0.8824166666666666.\n",
      "[I 2026-02-07 21:49:39,070] Trial 7 finished with value: 0.10675 and parameters: {'num_hidden_layers': 8, 'num_epochs': 67, 'learning_rate': 0.059148930289744196, 'weight_decay': 0.00035067176023759677, 'dropout_raye': 0.2885065318756289, 'optimizer': 'RMSprop', 'batch_size': 512, 'neurons_per_layer': 152}. Best is trial 1 with value: 0.8824166666666666.\n",
      "[I 2026-02-07 21:52:43,838] Trial 8 finished with value: 0.5671666666666667 and parameters: {'num_hidden_layers': 8, 'num_epochs': 64, 'learning_rate': 0.017569736827333933, 'weight_decay': 0.0007071170918279999, 'dropout_raye': 0.33328952490101327, 'optimizer': 'Adam', 'batch_size': 64, 'neurons_per_layer': 168}. Best is trial 1 with value: 0.8824166666666666.\n",
      "[I 2026-02-07 22:13:22,228] Trial 9 finished with value: 0.8963333333333333 and parameters: {'num_hidden_layers': 10, 'num_epochs': 210, 'learning_rate': 0.02456756919880403, 'weight_decay': 0.0003733383714923822, 'dropout_raye': 0.25453699388900697, 'optimizer': 'Adagrad', 'batch_size': 32, 'neurons_per_layer': 128}. Best is trial 9 with value: 0.8963333333333333.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(optuna_objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6a250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
