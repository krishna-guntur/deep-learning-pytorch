{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be643221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950740d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d37641c1070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e50c382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/krish/Datasets/fashion_mnist/fashion-mnist_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aada2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8168fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f961be",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaf552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels, transforms):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.features[index].reshape(28,28)\n",
    "        image = image.astype(np.uint8)\n",
    "        image = np.stack([image]*3, axis=-1)\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        image = self.transforms(image)\n",
    "\n",
    "        return image, torch.tensor(self.labels[index], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05006bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = customDataset(X_train, y_train, transforms=custom_transforms)\n",
    "test_dataset = customDataset(X_test, y_test, transforms=custom_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632b8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c4d68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish/miniconda3/envs/torchenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/krish/miniconda3/envs/torchenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83af2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d014700",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "\n",
    "vgg16 = vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25a1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d6d4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg16.classifier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f235f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after Epoch 1: 4.703159071272239\n",
      "Loss after Epoch 2: 3.3773375515593216\n",
      "Loss after Epoch 3: 2.9372054007835686\n",
      "Loss after Epoch 4: 2.616177542018704\n",
      "Loss after Epoch 5: 2.4316434050851967\n",
      "Loss after Epoch 6: 2.2855767420842312\n",
      "Loss after Epoch 7: 2.148963691521203\n",
      "Loss after Epoch 8: 1.9309064302651677\n",
      "Loss after Epoch 9: 1.8485559804539662\n",
      "Loss after Epoch 10: 1.754582381390719\n",
      "Loss after Epoch 11: 1.766329962942109\n",
      "Loss after Epoch 12: 1.6165637952290126\n",
      "Loss after Epoch 13: 1.4061846072145272\n",
      "Loss after Epoch 14: 1.5012081569757356\n",
      "Loss after Epoch 15: 1.512343488060651\n",
      "Loss after Epoch 16: 1.4921564131072955\n",
      "Loss after Epoch 17: 1.2491708460872815\n",
      "Loss after Epoch 18: 1.3172402975014847\n",
      "Loss after Epoch 19: 1.3053437740109075\n",
      "Loss after Epoch 20: 1.222762259640831\n",
      "Loss after Epoch 21: 1.2965321442852655\n",
      "Loss after Epoch 22: 1.2155123878661698\n",
      "Loss after Epoch 23: 1.1849590594447363\n",
      "Loss after Epoch 24: 1.1069969962190953\n",
      "Loss after Epoch 25: 1.1514047908949578\n",
      "Loss after Epoch 26: 1.1381953168679502\n",
      "Loss after Epoch 27: 1.1171582653660153\n",
      "Loss after Epoch 28: 1.0019730947102516\n",
      "Loss after Epoch 29: 1.1005473233794874\n",
      "Loss after Epoch 30: 1.0950830806065142\n",
      "Loss after Epoch 31: 1.0619096216917683\n",
      "Loss after Epoch 32: 0.9527408410920088\n",
      "Loss after Epoch 33: 0.9982550760331321\n",
      "Loss after Epoch 34: 0.9961251447793984\n",
      "Loss after Epoch 35: 0.9556598735019293\n",
      "Loss after Epoch 36: 1.0936549003722291\n",
      "Loss after Epoch 37: 0.9543678393722921\n",
      "Loss after Epoch 38: 0.9012438471417532\n",
      "Loss after Epoch 39: 0.8143076918565555\n",
      "Loss after Epoch 40: 0.9501801235297478\n",
      "Loss after Epoch 41: 0.9269228074238285\n",
      "Loss after Epoch 42: 0.8984261782691689\n",
      "Loss after Epoch 43: 0.9938775213715871\n",
      "Loss after Epoch 44: 0.7861526892842976\n",
      "Loss after Epoch 45: 0.821297501241105\n",
      "Loss after Epoch 46: 0.8243372387502994\n",
      "Loss after Epoch 47: 0.9308041515142769\n",
      "Loss after Epoch 48: 0.9367305599779456\n",
      "Loss after Epoch 49: 0.7883155457063822\n",
      "Loss after Epoch 50: 0.8350386864900998\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    Epoch_loss = 0\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        output = vgg16(batch_features)\n",
    "\n",
    "        loss = criterion(output, batch_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        Epoch_loss += loss.item()\n",
    "\n",
    "    avg_epoch_loss = Epoch_loss/len(batch_features)\n",
    "    print(f\"Loss after Epoch {epoch+1}: {avg_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8edda379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9285\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "vgg16.eval()\n",
    "\n",
    "# Evaluation Code on test data\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "\n",
    "        batch_features, batch_labels = batch_features.to(device=device), batch_labels.to(device=device)\n",
    "\n",
    "        outputs = vgg16(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += batch_labels.shape[0]\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    print(f\"Test accuracy: {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "813ceb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9993125\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Code on test data\n",
    "\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "        batch_features, batch_labels = batch_features.to(device=device), batch_labels.to(device=device)\n",
    "\n",
    "        outputs = vgg16(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total_train += batch_labels.shape[0]\n",
    "        correct_train += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    print(f\"Train accuracy: {correct_train/total_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa0162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
